{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the relavent modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from moviepy.editor import *\n",
    "from IPython.display import HTML\n",
    "from scipy.ndimage.measurements import label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class to handle feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFeatures:\n",
    "    \"\"\"\n",
    "    This class manages feature extraction for the given images.\n",
    "    It provides 4 public API's, which can be called to get the \n",
    "    desired features.\n",
    "    Public APIs ::\n",
    "    1) convert_color\n",
    "    2) color_hist_features\n",
    "    3) bin_spatial_features\n",
    "    4) get_hog_features\n",
    "    \"\"\"\n",
    "    def __init__(self, color_space = 'BGR', spatial_size = (32,32), bins_range=(0,256), \n",
    "                 nbins = 32, orient = 9, pix_per_cell = 8, cell_per_block=2):\n",
    "        \"\"\"\n",
    "        This is the constructor for the class CFeatures.\n",
    "        It initializes all the member variables of this class.\n",
    "        These member variables represent tunable hyper-parameters. \n",
    "        \"\"\"\n",
    "        self.color_space = color_space\n",
    "        self.spatial_size = spatial_size\n",
    "        self.bins_range = bins_range\n",
    "        self.nbins = nbins\n",
    "        self.orient = orient\n",
    "        self.pix_per_cell = pix_per_cell\n",
    "        self.cell_per_block = cell_per_block\n",
    "        \n",
    "    def convert_color(self, image):\n",
    "        \"\"\"\n",
    "        This function converts the given image into the desired color space.\n",
    "        \n",
    "        @param[in] : image : Image for which color conversion is desired.\n",
    "        @return color_converted_image : New image with converted colors.\n",
    "        \"\"\"\n",
    "        if self.color_space != 'BGR':\n",
    "            if self.color_space == 'HSV':\n",
    "                color_converted_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "            elif self.color_space == 'HLS':\n",
    "                color_converted_image = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "            elif self.color_space == 'RGB':\n",
    "                color_converted_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            elif self.color_space == 'YUV':\n",
    "                color_converted_image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "            elif self.color_space == 'YCrCb':\n",
    "                color_converted_image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "        else: \n",
    "            color_converted_image = np.copy(image)\n",
    "\n",
    "        return color_converted_image\n",
    "\n",
    "    def color_hist_features(self, image):\n",
    "        \"\"\"\n",
    "        This function extract color histogram features from a given image.\n",
    "        \n",
    "        @param[in] : image : Image for which features need to be extracted.\n",
    "        @return hist_features : Histogram of color features.\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute the histogram of the 3 channels seprately\n",
    "        channel_0 = np.histogram(image[:,:,0], self.nbins, self.bins_range)\n",
    "        channel_1 = np.histogram(image[:,:,1], self.nbins, self.bins_range)\n",
    "        channel_2 = np.histogram(image[:,:,2], self.nbins, self.bins_range)\n",
    "        # Generating bin centers\n",
    "        edges = channel_0[1]\n",
    "        bin_centers = (edges[1:] + edges[0:len(edges)-1])/2\n",
    "        # Concatenate the histograms into a single feature vector\n",
    "        hist_features = np.concatenate((channel_0[0], channel_1[0], channel_2[0]))\n",
    "\n",
    "        # Return the feature vector\n",
    "        return hist_features\n",
    "    \n",
    "    def bin_spatial_features(self, image):\n",
    "        \"\"\"\n",
    "        This function extracts spatial color features form a given image.\n",
    "\n",
    "        @param[in] : image : Input image\n",
    "        @return bin_spatial_color_features : Feature vector with spatially \n",
    "        binned feature vectors.\n",
    "        \"\"\"\n",
    "        bin_spatial_color_features = cv2.resize(image, self.spatial_size).ravel() \n",
    "        # Return the feature vector\n",
    "        return bin_spatial_color_features\n",
    "\n",
    "    def get_hog_features(self, img, visualise=False, feature_vector=True):\n",
    "        \"\"\"\n",
    "        This function extracts the HOG features from an image.\n",
    "        \n",
    "        @param[in] : img : input image\n",
    "        @param[in] : visualise : Flag to return hog image.\n",
    "        @param[in] : feature_vec : Flag to indicate the unrolling of feature vector.\n",
    "\n",
    "        \"\"\"\n",
    "        if visualise:\n",
    "            features, hog_image = hog(img, orientations=self.orient,\n",
    "                              pixels_per_cell=(self.pix_per_cell, self.pix_per_cell), \\\n",
    "                              cells_per_block=(self.cell_per_block, self.cell_per_block), \\\n",
    "                              transform_sqrt=True, visualise=visualise, feature_vector=feature_vector)\n",
    "\n",
    "            return features, hog_image\n",
    "\n",
    "        else:\n",
    "            features = hog(img, orientations=self.orient,\n",
    "                              pixels_per_cell=(self.pix_per_cell, self.pix_per_cell), \\\n",
    "                              cells_per_block=(self.cell_per_block, self.cell_per_block), \\\n",
    "                              transform_sqrt=True, visualise=visualise, feature_vector=feature_vector)\n",
    "            return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class to handle the pipeline for training the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CClassifier:\n",
    "    \"\"\"\n",
    "    This class provides the method for training the classifier.\n",
    "    It also saves the final model and the feature scaler to the disk.\n",
    "    For training the classifier, the class provides 1 public API \n",
    "    and internally makes use of 4 private methods.\n",
    "    \n",
    "    Public API : train_classifier\n",
    "    \n",
    "    Private methods :\n",
    "    1) __classifier\n",
    "    2) __data_pre_process\n",
    "    3) __augment_brightness\n",
    "    4) __extract_features\n",
    "    \"\"\"\n",
    "    def __init__(self, obj_features):\n",
    "        \"\"\"\n",
    "        This is the constructor for the class CClassifier\n",
    "        \"\"\"        \n",
    "        # Object of the CFeatures class\n",
    "        self.obj_features = obj_features\n",
    "    \n",
    "    def train_classifier(self, not_cars, cars, aug_data=True):\n",
    "        \"\"\"\n",
    "        This function executes the pipeline for training the classifier.\n",
    "        It reads in the images, extracts the features, pre-processes the data and trains.\n",
    "        After training, it saves the classifier on the disk.\n",
    "        \n",
    "        @param[in] not_cars : List of all the non car images\n",
    "        @param[in] cars : List of the car images\n",
    "        @param[in] aug_data : Flag to indicate if data augumentation should be done or not.\n",
    "        \"\"\"\n",
    "\n",
    "        # Create a list to append feature vectors to\n",
    "        not_car_features = []\n",
    "\n",
    "        # Iterate through the list of car images\n",
    "        for img in not_cars:\n",
    "            # Read in each one by one in BGR format\n",
    "            image = cv2.imread(img) \n",
    "            # Extract the features from the image\n",
    "            not_car_features.append(self.__extract_features(image))\n",
    "            if aug_data:\n",
    "                aug_image = self.__augment_brightness(image)\n",
    "                not_car_features.append(self.__extract_features(aug_image))\n",
    "\n",
    "        # Create a list to append feature vectors to\n",
    "        car_features = []\n",
    "\n",
    "        # Iterate through the list of car images\n",
    "        for img in cars:\n",
    "            # Read in each one by one in BGR format\n",
    "            image = cv2.imread(img)\n",
    "            # Extract the features from the image\n",
    "            car_features.append(self.__extract_features(image))\n",
    "            if aug_data:\n",
    "                aug_image = self.__augment_brightness(image)\n",
    "                car_features.append(self.__extract_features(aug_image))\n",
    "\n",
    "        # Define a labels vector based on features lists\n",
    "        label_vector = np.hstack((np.ones(len(car_features)), np.zeros(len(not_car_features))))\n",
    "        \n",
    "        # Preprocess the data\n",
    "        feature_scaler, X_train, X_test, y_train, y_test = \\\n",
    "                    self.__data_pre_process(car_features, not_car_features, label_vector)\n",
    "\n",
    "        # Save feature scaler\n",
    "        filename = 'feature_scaler.sav'\n",
    "        pickle.dump(feature_scaler, open(filename, 'wb'))\n",
    "        \n",
    "        svc = self.__classifier(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        # Save the classifier\n",
    "        filename = 'finalized_model.sav'\n",
    "        pickle.dump(svc, open(filename, 'wb'))\n",
    "            \n",
    "    def __classifier(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"\n",
    "        This function creates a classifier and subsequently trains it.\n",
    "        \n",
    "        @param[in] : X_train : Training data\n",
    "        @param[in] : X_test : Test data\n",
    "        @param[in] : y_train : Trainign labels\n",
    "        @param[in] : y_test : Test labels\n",
    "        @return : svc : Final model\n",
    "        \"\"\"\n",
    "        # Build a linear SVM classifier\n",
    "        svc = LinearSVC()\n",
    "        # Check the training time for the SVC\n",
    "        t=time.time()\n",
    "        svc.fit(X_train, y_train)\n",
    "        t2 = time.time()\n",
    "        print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "        # Check the score of the SVC\n",
    "        print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "        # Check the prediction time for a single sample\n",
    "        t=time.time()\n",
    "        n_predict = 10\n",
    "        print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "        print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "        t2 = time.time()\n",
    "        print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')\n",
    "\n",
    "        return svc\n",
    "    \n",
    "    def __data_pre_process(self, car_features, not_car_features, label_vector):\n",
    "        \"\"\"\n",
    "        This function pre processes the training data. First it normalizes\n",
    "        the training data then it shuffles it and splits into training and test sets.\n",
    "        \n",
    "        @param[in] : car_features\n",
    "        @param[in] : not_car_features\n",
    "        @param[in] : label_vector\n",
    "        @return    :  feature_scaler, X_train, X_test, y_train, y_test\n",
    "        \"\"\"\n",
    "        combined_feature_array = np.vstack((car_features, not_car_features)).astype(np.float64)                        \n",
    "        feature_scaler = StandardScaler().fit(combined_feature_array)\n",
    "        normalized_combined_feature_array = feature_scaler.transform(combined_feature_array)\n",
    "\n",
    "        # Split up data into randomized training and test sets\n",
    "        rand_state = 100\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "        normalized_combined_feature_array, label_vector, test_size=0.25, random_state=rand_state)\n",
    "\n",
    "        return feature_scaler, X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def __augment_brightness(self, image):\n",
    "        \"\"\"\n",
    "        This function adds random brighteness to the input images\n",
    "        \n",
    "        @param[in] : image : Input image \n",
    "        @return : image1 : Augumented image.\n",
    "        \"\"\"\n",
    "        image1 = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "        image1 = np.array(image1, dtype = np.float64)\n",
    "        random_bright = .5+np.random.uniform()\n",
    "        image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "        image1[:,:,2][image1[:,:,2]>255]  = 255\n",
    "        image1 = np.array(image1, dtype = np.uint8)\n",
    "        image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2BGR)\n",
    "        return image1\n",
    "    \n",
    "    def __extract_features(self, image):\n",
    "        \"\"\"\n",
    "        This function extracts spatial color features as well as HOG features from the image.\n",
    "        \n",
    "        @param[in] : image : Image from which features need to be extracted.\n",
    "        @return : features : Vector containing all the features.\n",
    "        \"\"\"\n",
    "        image = self.obj_features.convert_color(image)\n",
    "\n",
    "        # Extract binned spatial color features\n",
    "        spatial_features = self.obj_features.bin_spatial_features(image)\n",
    "\n",
    "        # Extract features from color histogram\n",
    "        hist_features = self.obj_features.color_hist_features(image)\n",
    "\n",
    "        # Extract HOG features for all the channels\n",
    "        hog_feature = []\n",
    "        for channel in range(image.shape[2]):\n",
    "            hog_feature_channel = self.obj_features.get_hog_features(image[:,:,channel])\n",
    "            hog_feature.append(hog_feature_channel)\n",
    "\n",
    "        hog_feature = np.ravel(hog_feature)\n",
    "\n",
    "        # Append the new feature vector to the features list\n",
    "        features = np.concatenate((spatial_features, hist_features, hog_feature))\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class to handle vehicle detection pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDetectionAttributes:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.centroid = []\n",
    "        self.x1y1 = []\n",
    "        self.x2y2 = []\n",
    "        self.num_detections = 0\n",
    "        self.this_frame_detected = False\n",
    "        self.num_not_detected = 0\n",
    "        \n",
    "class CVehicleDetection:\n",
    "    \"\"\"\n",
    "    This class manages the pipeline for detecton of vehicle in a given image.\n",
    "    It provides 1 public API, process_image(), for detecting vehicles. \n",
    "    Internally, it has 4 private methods, which help in different stages \n",
    "    of the detection pipeline (from implementing the core algorithm to drawing the boxes).\n",
    "    \n",
    "    Public API :: process_image\n",
    "    \n",
    "    Private methods ::\n",
    "    1) __find_cars\n",
    "    2) __add_heat\n",
    "    3) __apply_threshold\n",
    "    4) __draw_labeled_bboxes\n",
    "    5) __iir_filter\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, obj_features, scale = [1.5], ystart=[400], ystop=[655], \n",
    "                 xstart=[0], xstop=[1280], false_detection_threshold=2, \n",
    "                 iir_filter=True, cells_per_step=2, debug_plotting=False):\n",
    "        \"\"\"\n",
    "        This is the constructor for the class CVehicleDetection.\n",
    "        It initializes the hyper parameters required for detection.\n",
    "        It also loads the classfier and the feature scale from the disk.\n",
    "        \"\"\"\n",
    "        # Sanity checks\n",
    "        assert len(scale)==len(ystart) and len(scale)==len(ystop) and len(ystart)==len(ystop), \\\n",
    "        \"Length of sclae, ystart and ystop should be the same !\"\n",
    "        \n",
    "        assert len(scale)==len(xstart) and len(scale)==len(xstop) and len(xstart)==len(xstop), \\\n",
    "        \"Length of sclae, xstart and xstop should be the same !\"\n",
    "        \n",
    "        self.obj_features = obj_features\n",
    "        self.ystart = ystart\n",
    "        self.ystop = ystop\n",
    "        self.scale = scale\n",
    "        self.xstart = xstart\n",
    "        self.xstop = xstop\n",
    "        self.false_detection_threshold = false_detection_threshold\n",
    "        self.heat_map = np.zeros((720, 1280)).astype(np.float)\n",
    "        self.car_detected_windows = []\n",
    "        self.iir_filter = iir_filter\n",
    "        self.cells_per_step = cells_per_step\n",
    "        # Keep track of the vehicles detected\n",
    "        self.detected_vehicle = []\n",
    "        self.debug_plotting = debug_plotting\n",
    "        \n",
    "        # Load the saved model \n",
    "        filename = 'finalized_model.sav'\n",
    "        with open(filename, mode='rb') as file:\n",
    "            self.svc = pickle.load(file)\n",
    "\n",
    "        # Load the saved feature scaler\n",
    "        filename = 'feature_scaler.sav'\n",
    "        with open(filename, mode='rb') as file:\n",
    "            self.X_scaler = pickle.load(file)\n",
    "            \n",
    "    def process_image(self, image):\n",
    "        \"\"\"\n",
    "        This function executes the pipeline for detecting a car on a single image.\n",
    "        \n",
    "        @param[in] : image : Input image\n",
    "        @return : image with vehicles detected.\n",
    "        \"\"\"\n",
    "\n",
    "        # Detect cars !\n",
    "        self.__find_cars(image)\n",
    "        \n",
    "        #non_empty = [x for x in self.car_detected_windows if x != []]\n",
    "        \n",
    "        self.__add_heat()\n",
    "        self.__apply_threshold()\n",
    "\n",
    "        # Find final boxes from heatmap using label function\n",
    "        labels = label(self.heat_map)\n",
    "        \n",
    "        window_img = np.copy(image)\n",
    "        \n",
    "        if self.iir_filter == False:\n",
    "            window_img = self.__draw_labeled_bboxes(image, labels) \n",
    "            self.car_detected_windows = []\n",
    "        else:\n",
    "            window_img = self.__iir_filter(image, window_img, labels)\n",
    "                    \n",
    "        if self.debug_plotting:\n",
    "            plt.imshow(self.heat_map, cmap='hot')\n",
    "            plt.title(\"Heat Map\")\n",
    "            plt.show()\n",
    "        \n",
    "        # reset the heat map\n",
    "        self.heat_map = np.zeros((720, 1280)).astype(np.float)\n",
    "            \n",
    "        return window_img\n",
    "\n",
    "    \n",
    "    def __iir_filter(self, image, window_img, labels):\n",
    "        \"\"\"\n",
    "        This function filters out the detections to remove false positives\n",
    "        and improve the bounding boxes of the detected ones by iir filtering\n",
    "        @param[in] window_img : image to be drawn on.\n",
    "        \"\"\"\n",
    "        \n",
    "        colors = [[0,0,255],[0,255,0],[255,0,0],[255,255,0],[0,255,255],[255,0,255],[255,255,255]]\n",
    "        filter_coeff = 0.7\n",
    "        aspect_ratio = 1.5\n",
    "        \n",
    "        # Reset the detection flag for this frame\n",
    "        for car in self.detected_vehicle:\n",
    "            car.this_frame_detected = False\n",
    "\n",
    "        for car_number in range(1, labels[1]+1):\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            # Identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), \n",
    "                    (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            obj_detection = CDetectionAttributes()\n",
    "            # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "            obj_detection.centroid = [int((bbox[0][0] + bbox[1][0]) / 2), \n",
    "                                      int((bbox[0][1] + bbox[1][1]) / 2)]\n",
    "            obj_detection.x1y1 = [bbox[0][0] , bbox[0][1]]\n",
    "            obj_detection.x2y2 = [bbox[1][0] , bbox[1][1]]\n",
    "\n",
    "            # Iterate over the exsisting objects to find similar vehicles\n",
    "            object_found = False\n",
    "\n",
    "            for car in self.detected_vehicle:\n",
    "                distance = math.hypot(car.centroid[0] - obj_detection.centroid[0], \n",
    "                                      car.centroid[1] - obj_detection.centroid[1])\n",
    "                if distance < 50:\n",
    "                    # Increment the detection count\n",
    "                    car.num_detections += 1\n",
    "                    car.num_not_detected = 0\n",
    "\n",
    "                    # Filter the centroid to the mean of the centroids.\n",
    "                    car.centroid[0] = int((filter_coeff*car.centroid[0] + (1-filter_coeff)*obj_detection.centroid[0]))\n",
    "                    car.centroid[1] = int((filter_coeff*car.centroid[1] + (1-filter_coeff)*obj_detection.centroid[1]))\n",
    "\n",
    "                    # Filter the edges\n",
    "                    car.x1y1[0] = int((filter_coeff*car.x1y1[0] + (1-filter_coeff)*obj_detection.x1y1[0]))\n",
    "                    car.x1y1[1] = int((filter_coeff*car.x1y1[1] + (1-filter_coeff)*obj_detection.x1y1[1]))\n",
    "\n",
    "                    car.x2y2[0] = int((filter_coeff*car.x2y2[0] + (1-filter_coeff)*obj_detection.x2y2[0]))\n",
    "                    car.x2y2[1] = int((filter_coeff*car.x2y2[1] + (1-filter_coeff)*obj_detection.x2y2[1]))\n",
    "\n",
    "                    # Scale the box with proper aspect ratio\n",
    "                    if (car.x2y2[1] - car.x1y1[1])*aspect_ratio < (car.x2y2[0] - car.x1y1[0]):\n",
    "                        car.x2y2[0] = car.centroid[0] + int(((car.x2y2[1] - car.x1y1[1])*aspect_ratio)/2)\n",
    "                        car.x1y1[0] = car.centroid[0] - int(((car.x2y2[1] - car.x1y1[1])*aspect_ratio)/2)\n",
    "\n",
    "                    object_found = True\n",
    "                    car.this_frame_detected = True\n",
    "                    break\n",
    "\n",
    "            if object_found == False:\n",
    "                # Append the object to the list of detected objects if both sides are > 32 pixels\n",
    "                if (abs(obj_detection.x2y2[0] - obj_detection.x1y1[0]) > 32) and \\\n",
    "                   (abs(obj_detection.x2y2[1] - obj_detection.x1y1[1]) > 32):\n",
    "\n",
    "                        obj_detection.num_detections = 1\n",
    "                        obj_detection.this_frame_detected = True\n",
    "                        obj_detection.continuous_detection_count = 1\n",
    "                        self.detected_vehicle.append(obj_detection)\n",
    "\n",
    "        if len(self.car_detected_windows) == 5:\n",
    "            self.car_detected_windows.pop(0)\n",
    "\n",
    "        for itera,car in enumerate(self.detected_vehicle):\n",
    "            # If the object was not found in this frame, reduce the detection count\n",
    "            if car.this_frame_detected == False:\n",
    "                car.num_detections -= 1\n",
    "                car.num_not_detected += 1\n",
    "\n",
    "            if car.num_not_detected == 7:\n",
    "                self.detected_vehicle.pop(itera)\n",
    "                break\n",
    "\n",
    "            if car.num_detections > 5:\n",
    "                window_img = cv2.rectangle(image, (car.x1y1[0], car.x1y1[1]), \n",
    "                                          (car.x2y2[0], car.x2y2[1]), colors[itera], 3)\n",
    "        \n",
    "        return window_img\n",
    "        \n",
    "    def __find_cars(self, image):\n",
    "        \"\"\"\n",
    "        NOTE : This function is adapted from the Udacity lessons.\n",
    "        This function implements a sliding window algorithm to extract the\n",
    "        features from an image and then execute the classifier on it.\n",
    "        @param[in] : image : Input image\n",
    "        \n",
    "        \"\"\"\n",
    "        car_detected_windows = []\n",
    "        colors = [[0,0,255],[0,255,0],[255,0,0],[255,255,0],[0,255,255],[255,0,255],[255,255,255]]\n",
    "        debug_plotting = False\n",
    "        \n",
    "        for iteration, _ in enumerate(self.scale):\n",
    "            draw_image = np.copy(image)\n",
    "            img_tosearch = image[self.ystart[iteration]:self.ystop[iteration],\n",
    "                                 self.xstart[iteration]:self.xstop[iteration],:]\n",
    "        \n",
    "            ctrans_tosearch = self.obj_features.convert_color(img_tosearch)\n",
    "        \n",
    "            if self.scale[iteration] != 1:\n",
    "                imshape = ctrans_tosearch.shape\n",
    "                ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/self.scale[iteration]), \\\n",
    "                                                               np.int(imshape[0]/self.scale[iteration])))\n",
    "\n",
    "            ch1 = ctrans_tosearch[:,:,0]\n",
    "            ch2 = ctrans_tosearch[:,:,1]\n",
    "            ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "            # Define blocks and steps\n",
    "            nxblocks = (ch1.shape[1] // self.obj_features.pix_per_cell) - self.obj_features.cell_per_block + 1\n",
    "            nyblocks = (ch1.shape[0] // self.obj_features.pix_per_cell) - self.obj_features.cell_per_block + 1\n",
    "\n",
    "            # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "            window = 64\n",
    "            nblocks_per_window = (window // self.obj_features.pix_per_cell)- self.obj_features.cell_per_block + 1\n",
    "            nxsteps = (nxblocks - nblocks_per_window) // self.cells_per_step + 1\n",
    "            nysteps = (nyblocks - nblocks_per_window) // self.cells_per_step + 1\n",
    "\n",
    "            # Compute individual channel HOG features for the entire image\n",
    "            hog1 = self.obj_features.get_hog_features(ch1, feature_vector=False)\n",
    "            hog2 = self.obj_features.get_hog_features(ch2, feature_vector=False)\n",
    "            hog3 = self.obj_features.get_hog_features(ch3, feature_vector=False)\n",
    "\n",
    "            for xb in range(nxsteps):\n",
    "                for yb in range(nysteps):\n",
    "                    ypos = yb*self.cells_per_step\n",
    "                    xpos = xb*self.cells_per_step\n",
    "                    # Extract HOG for this patch\n",
    "                    hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                    hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                    hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                    hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "                    xleft = xpos*self.obj_features.pix_per_cell\n",
    "                    ytop = ypos*self.obj_features.pix_per_cell\n",
    "\n",
    "                    # Extract the image patch\n",
    "                    subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "\n",
    "                    # Get color features\n",
    "                    spatial_features = self.obj_features.bin_spatial_features(subimg)\n",
    "                    hist_features = self.obj_features.color_hist_features(subimg)\n",
    "\n",
    "                    # Scale features and make a prediction\n",
    "                    test_features = self.X_scaler.transform(np.hstack((spatial_features, \\\n",
    "                                                            hist_features, hog_features)).reshape(1, -1)) \n",
    "                    test_prediction = self.svc.predict(test_features)\n",
    "\n",
    "                    if self.debug_plotting:\n",
    "                        xbox_left = np.int(xleft*self.scale[iteration]) + self.xstart[iteration]\n",
    "                        ytop_draw = np.int(ytop*self.scale[iteration])\n",
    "                        win_draw = np.int(window*self.scale[iteration])\n",
    "                        cv2.rectangle(draw_image, (xbox_left, ytop_draw + self.ystart[iteration]), \n",
    "                                  (xbox_left + win_draw, ytop_draw + win_draw + self.ystart[iteration]), \n",
    "                                  colors[iteration], 5)\n",
    "\n",
    "                    if test_prediction == 1:\n",
    "                        xbox_left = np.int(xleft*self.scale[iteration]) + self.xstart[iteration]\n",
    "                        ytop_draw = np.int(ytop*self.scale[iteration])\n",
    "                        win_draw = np.int(window*self.scale[iteration])\n",
    "                        car_detected_windows.append(((xbox_left, ytop_draw + self.ystart[iteration]), \n",
    "                                          (xbox_left + win_draw, ytop_draw + win_draw + self.ystart[iteration])))\n",
    "            if self.debug_plotting:\n",
    "                plt.imshow(cv2.cvtColor(draw_image, cv2.COLOR_BGR2RGB))\n",
    "                plt.show()\n",
    "                \n",
    "        self.car_detected_windows.append(car_detected_windows)\n",
    "        \n",
    "    def __add_heat(self):\n",
    "        \"\"\"\n",
    "        This function generates a heat map based on the detected windows.\n",
    "        \"\"\"\n",
    "        # Flatten the list containing the detected windows\n",
    "        flat_list = [item for sublist in self.car_detected_windows for item in sublist]\n",
    "        \n",
    "        for box in flat_list:\n",
    "            # Add += 1 for all pixels inside each bbox\n",
    "            # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "            self.heat_map[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "            \n",
    "    def __apply_threshold(self):\n",
    "        \"\"\"\n",
    "        This function filters out the false positives.\n",
    "        \"\"\"\n",
    "        # Zero out pixels below the threshold\n",
    "        self.heat_map[self.heat_map <= self.false_detection_threshold] = 0\n",
    "        \n",
    "    def __draw_labeled_bboxes(self, img, labels):\n",
    "        \"\"\"\n",
    "        This function draws the boxes on the detected window.\n",
    "        @param[in] : img : Input image\n",
    "        @return[in] : labels : pixels with the detected vehicles.\n",
    "        @return : img : Image with boxes drawn\n",
    "        \"\"\"\n",
    "        # Iterate through all detected cars\n",
    "        for car_number in range(1, labels[1]+1):\n",
    "            # Find pixels with each car_number label value\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            # Identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Define a bounding box based on min/max x and y\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # Draw the box on the image\n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 5)\n",
    "        # Return the image\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to read images from a given dir and its sub-dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_images(root_dir):\n",
    "    \"\"\"\n",
    "    This function iterates over all the sub directories of a given root dir \n",
    "    and appends the names of the png images to a list.\n",
    "    \n",
    "    @param[in] : Path of the root dir.\n",
    "    @return : image_data : List of names of all images. \n",
    "    \"\"\"\n",
    "    \n",
    "    sub_dirs = [x[0] for x in os.walk(root_dir)]\n",
    "    image_data = []\n",
    "    for sub_dir in sub_dirs:\n",
    "        image_path = os.path.join(root_dir, sub_dir)\n",
    "        images = glob.glob(os.path.join(image_path,'*.png'))\n",
    "        for image in images:\n",
    "            image_data.append(image)\n",
    "    \n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver function to test the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_classifier(image_path, obj_vehicle_detection):\n",
    "    \"\"\"\n",
    "    This function tests the classifier on the test set of images.\n",
    "    \n",
    "    @param[in] : image_path : Path to the test images\n",
    "    @param[in] : obj_vehicle_detection : Object of the vehicle detection class\n",
    "    \"\"\"\n",
    "    test_images = os.listdir(image_path)\n",
    "\n",
    "    # Loop over the dir containing test images and store the final images\n",
    "    for image_name in test_images:\n",
    "        image_path = os.path.join('test_images', image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Process the test image\n",
    "        window_img = obj_vehicle_detection.process_image(image)\n",
    "        \n",
    "        # Display the final image with vehicles detected\n",
    "        plt.imshow(cv2.cvtColor(window_img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"Color Space == YCrCb, Cell Per Pixel == 8, Cells Per Block == 4, Orientations == 11\")\n",
    "        plt.show()\n",
    "        output_image_path = os.path.join('output_test_images', 'final_'+ image_name )\n",
    "        plt.imsave(output_image_path, cv2.cvtColor(window_img,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver function to process video frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_video(video_name, obj_vehicle_detection):\n",
    "    \"\"\"\n",
    "    This function processes a given test video by calling the \n",
    "    process_image function on every frame of the video.\n",
    "    \n",
    "    @param[in] : video_name : Name of the test video\n",
    "    @param[in] : obj_vehicle_detection : Object of the vehicle detection class\n",
    "    \"\"\"\n",
    "    clip = VideoFileClip(video_name)\n",
    "    final_video = os.path.join('final_' + video_name)\n",
    "    video_clip = clip.fl_image(obj_vehicle_detection.process_image)\n",
    "    %time video_clip.write_videofile(final_video, audio=False)\n",
    "\n",
    "    HTML(\"\"\"\n",
    "        <video width=\"960\" height=\"540\" controls>\n",
    "        <source src=\"{0}\">\n",
    "        </video>\n",
    "        \"\"\".format(final_video))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def data_exploration(not_cars, cars, obj_features):\n",
    "    \n",
    "    print(\"Total training samples for class not_cars == \", len(not_cars))\n",
    "    print(\"Total training samples for class car == \", len(cars))\n",
    "    \n",
    "    # Visualize hog images\n",
    "    car_image = cv2.imread(cars[100])\n",
    "    features, hog_image = obj_features.get_hog_features(cv2.cvtColor(car_image, cv2.COLOR_BGR2GRAY), \n",
    "                                                            visualise=True)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(car_image, cmap='gray')\n",
    "    plt.title(\"Original Car image\")\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(hog_image, cmap='gray')\n",
    "    plt.title(\"Hog Features - YCrCb\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize some not cars samples from the data set\n",
    "\n",
    "    fig, axes  = plt.subplots(nrows = 2, ncols = 2, figsize=(40,30))\n",
    "    for row in axes:\n",
    "        for col in row:\n",
    "            rand_index = np.random.randint(len(not_cars))\n",
    "            not_car_image = cv2.imread(not_cars[rand_index])\n",
    "            col.imshow(not_car_image)\n",
    "    \n",
    "    fig, axes  = plt.subplots(nrows = 2, ncols = 2, figsize=(40,30))   \n",
    "    for row in axes:\n",
    "        for col in row:\n",
    "            rand_index = np.random.randint(len(cars))\n",
    "            car_image = cv2.imread(cars[rand_index])\n",
    "            col.imshow(car_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main driver program to execute the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    This is the main driver function to execute the entire vehicle detection\n",
    "    pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the images\n",
    "    not_cars = read_images('C:\\\\Users\\\\rbahl\\\\CarND-Vehicle-Detection\\\\non-vehicles')\n",
    "    cars = read_images('C:\\\\Users\\\\rbahl\\\\CarND-Vehicle-Detection\\\\vehicles')\n",
    "    \n",
    "    # Create an object for feature detection and set the hyper-parameters.\n",
    "    obj_features = CFeatures(color_space = 'YCrCb', spatial_size = (32,32),\n",
    "                            bins_range=(0,256), nbins = 32, orient = 9, \n",
    "                            pix_per_cell = 8, cell_per_block=4)\n",
    "    \n",
    "    # Data exploration\n",
    "    data_exploration(not_cars, cars, obj_features)\n",
    "    \n",
    "    # Create an object to train and save the classifier.\n",
    "    obj_classifier = CClassifier(obj_features)\n",
    "    \n",
    "    # Train the classifier.\n",
    "    obj_classifier.train_classifier(not_cars, cars, aug_data=True)\n",
    "    \n",
    "    scale = [1.2, 1.5, 2.0]\n",
    "    ystart = [400, 400, 400]\n",
    "    ystop = [650, 680, 600]\n",
    "    xstart= [550, 550, 550]\n",
    "    xstop = [1280, 1280, 1280]\n",
    "\n",
    "\n",
    "    # Create an object for vehicle detection\n",
    "    obj_vehicle_detection = CVehicleDetection(obj_features, scale = scale, ystart=ystart, \n",
    "                                              ystop=ystop, xstart=xstart, xstop=xstop,\n",
    "                                              false_detection_threshold=2,iir_filter=False, debug_plotting=False)\n",
    "    \n",
    "    # Create an object for vehicle detection in video (irr_filter ==True)\n",
    "    obj_vehicle_detection_filter = CVehicleDetection(obj_features, scale = scale, ystart=ystart, \n",
    "                                              ystop=ystop, xstart=xstart, xstop=xstop, \n",
    "                                              false_detection_threshold=3,iir_filter=True)\n",
    "    # Test the classifier on test images.\n",
    "    image_path = 'test_images'\n",
    "    test_classifier(image_path, obj_vehicle_detection)\n",
    "    \n",
    "\n",
    "    # Test the pipeline on the video\n",
    "    video_name = 'project_video.mp4'\n",
    "    process_video(video_name, obj_vehicle_detection_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
